{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPikBYk//k9FCcGuXFwVBu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulArra/Machine-Learning/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Weight inputs, add bias, then use the activation function\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "bias = 4                   # b = 4\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
        "print(n.feedforward(x))    # 0.9990889488055994\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIDsy2EsZ-dD",
        "outputId": "c745052a-848b-418e-a0c9-e113cc0ff65a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1, epochs=10):\n",
        "        self.weights = np.zeros(input_size)\n",
        "        self.bias = 0\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def step(self, x):\n",
        "        return 1 if x >= 0 else 0\n",
        "\n",
        "    def predict(self, x):\n",
        "        z = np.dot(self.weights, x) + self.bias\n",
        "        return self.step(z)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        for _ in range(self.epochs):\n",
        "            for xi, yi in zip(X, y):\n",
        "                y_pred = self.predict(xi)\n",
        "                error = yi - y_pred\n",
        "                self.weights += self.lr * error * xi\n",
        "                self.bias += self.lr * error\n"
      ],
      "metadata": {
        "id": "RngU9dJHcDdu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_and = np.array([0, 0, 0, 1])\n",
        "\n",
        "perceptron_and = Perceptron(input_size=2)\n",
        "perceptron_and.train(X, y_and)\n",
        "\n",
        "print(\"AND Gate Results:\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {perceptron_and.predict(x)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjfhLFq6cxL3",
        "outputId": "d553e22e-0569-437e-df4a-61ab5c9f62a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate Results:\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 0\n",
            "[1 1] -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_or = np.array([0, 1, 1, 1])\n",
        "\n",
        "perceptron_or = Perceptron(input_size=2)\n",
        "perceptron_or.train(X, y_or)\n",
        "\n",
        "print(\"OR Gate Results:\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {perceptron_or.predict(x)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mSbnIHIc6FB",
        "outputId": "f3d5bbfc-30a2-4114-bbd9-3fdf3ddb4bdf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR Gate Results:\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden layer perceptrons\n",
        "perceptron1 = Perceptron(input_size=2)  # simulates OR\n",
        "perceptron2 = Perceptron(input_size=2)  # simulates AND (with inverted output)\n",
        "XOR_hidden = X\n",
        "\n",
        "# Train perceptrons manually for XOR logic\n",
        "# OR perceptron\n",
        "perceptron1.weights = np.array([1, 1])\n",
        "perceptron1.bias = -0.5\n",
        "\n",
        "# AND perceptron\n",
        "perceptron2.weights = np.array([1, 1])\n",
        "perceptron2.bias = -1.5\n",
        "\n",
        "# Output perceptron: AND-NOT combination\n",
        "def xor_predict(x):\n",
        "    h1 = perceptron1.predict(x)  # OR\n",
        "    h2 = perceptron2.predict(x)  # AND\n",
        "    # XOR = OR AND NOT AND\n",
        "    return perceptron_and.predict(np.array([h1, 1-h2]))\n",
        "\n",
        "print(\"XOR Gate Results:\")\n",
        "for x in X:\n",
        "    print(f\"{x} -> {xor_predict(x)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWcCgswYdfyj",
        "outputId": "5e26e040-2c79-443b-84dd-90729c8f2f95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XOR Gate Results:\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# MLP Class\n",
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_size, output_size, lr=0.1):\n",
        "        self.lr = lr\n",
        "        # Weights initialization\n",
        "        self.W1 = np.random.randn(input_size, hidden_size)\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size)\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.A1 = sigmoid(self.Z1)\n",
        "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "        self.A2 = sigmoid(self.Z2)\n",
        "        return self.A2\n",
        "\n",
        "    def backward(self, X, y, output):\n",
        "        m = X.shape[0]\n",
        "        dZ2 = output - y\n",
        "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "        dA1 = np.dot(dZ2, self.W2.T)\n",
        "        dZ1 = dA1 * sigmoid_derivative(self.A1)\n",
        "        dW1 = np.dot(X.T, dZ1) / m\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Update weights\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "\n",
        "    def train(self, X, y, epochs=10000):\n",
        "        for _ in range(epochs):\n",
        "            output = self.forward(X)\n",
        "            self.backward(X, y, output)\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward(X)\n",
        "        return np.round(output)\n"
      ],
      "metadata": {
        "id": "XEcAYq2Hdx5z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR Dataset\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Trying different number of neurons in hidden layer\n",
        "for hidden_neurons in [2, 4, 8]:\n",
        "    print(f\"\\nMLP with {hidden_neurons} hidden neurons:\")\n",
        "    mlp = MLP(input_size=2, hidden_size=hidden_neurons, output_size=1, lr=0.5)\n",
        "    mlp.train(X, y, epochs=10000)\n",
        "\n",
        "    for xi in X:\n",
        "        print(f\"{xi} -> {mlp.predict(np.array([xi]))[0][0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0pdIhwWd27U",
        "outputId": "72a8ac5f-ffbe-43e3-ab3d-dcdec4b092d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP with 2 hidden neurons:\n",
            "[0 0] -> 0.0\n",
            "[0 1] -> 1.0\n",
            "[1 0] -> 1.0\n",
            "[1 1] -> 0.0\n",
            "\n",
            "MLP with 4 hidden neurons:\n",
            "[0 0] -> 0.0\n",
            "[0 1] -> 1.0\n",
            "[1 0] -> 1.0\n",
            "[1 1] -> 0.0\n",
            "\n",
            "MLP with 8 hidden neurons:\n",
            "[0 0] -> 0.0\n",
            "[0 1] -> 1.0\n",
            "[1 0] -> 1.0\n",
            "[1 1] -> 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create a Perceptron object with a learning rate of 0.1\n",
        "perceptron = Perceptron(alpha=0.12)\n",
        "\n",
        "# Train the Perceptron on the training data\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained Perceptron to make predictions on the testing data\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the Perceptron\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLrPXrirgPTQ",
        "outputId": "e898297d-38da-4cfc-bd80-4b6fd6b4deab"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# --- Activation Function ---\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# --- Neuron Class ---\n",
        "class Neuron:\n",
        "    def __init__(self, input_size):\n",
        "        self.weights = np.random.randn(input_size)\n",
        "        self.bias = np.random.randn()\n",
        "\n",
        "    def feedforward(self, inputs):\n",
        "        total = np.dot(self.weights, inputs) + self.bias\n",
        "        return sigmoid(total)\n",
        "\n",
        "# --- Neural Network ---\n",
        "class OurNeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        # Hidden layer\n",
        "        self.hidden = [Neuron(input_size) for _ in range(hidden_size)]\n",
        "        # Output neuron\n",
        "        self.output = Neuron(hidden_size)\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        # Compute hidden layer outputs\n",
        "        hidden_outputs = np.array([h.feedforward(x) for h in self.hidden])\n",
        "        # Compute output neuron\n",
        "        out = self.output.feedforward(hidden_outputs)\n",
        "        return out\n",
        "\n",
        "network = OurNeuralNetwork(input_size=2, hidden_size=80)\n",
        "x = np.array([2, 3])\n",
        "print(\"Output:\", network.feedforward(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACTqnID_hA1R",
        "outputId": "cd84ec05-3751-48e6-ed5e-020a937aa2ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: 0.983421951689976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "varing the hidden layer size is effecting the  performing ( sometimes increase or decrease (unpredictable))"
      ],
      "metadata": {
        "id": "ARs7P_Nvh_bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.datasets as skl_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Load MNIST dataset\n",
        "data, labels = skl_data.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "data = data / 255.0  # normalize\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42, stratify=labels)\n",
        "X_train_small = X_train[:1000]\n",
        "y_train_small = y_train[:1000]\n",
        "\n",
        "# Initialize MLP\n",
        "mlp_mnist = MLPClassifier(hidden_layer_sizes=(30,), max_iter=50, verbose=1)\n",
        "mlp_mnist.fit(X_train_small, y_train_small)\n",
        "\n",
        "# Train and test accuracy\n",
        "train_acc_mnist = mlp_mnist.score(X_train, y_train)\n",
        "test_acc_mnist = mlp_mnist.score(X_test, y_test)\n",
        "\n",
        "print(f\"MNIST Train Accuracy: {train_acc_mnist*100:.2f}%\")\n",
        "print(f\"MNIST Test Accuracy: {test_acc_mnist*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "t-L2tftFoBqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "# Initialize MLP\n",
        "mlp_cancer = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, verbose=0, random_state=1)\n",
        "mlp_cancer.fit(X_train, y_train)\n",
        "\n",
        "# Train and test accuracy\n",
        "train_acc_cancer = mlp_cancer.score(X_train, y_train)\n",
        "test_acc_cancer = mlp_cancer.score(X_test, y_test)\n",
        "\n",
        "print(f\"Breast Cancer Train Accuracy: {train_acc_cancer*100:.2f}%\")\n",
        "print(f\"Breast Cancer Test Accuracy: {test_acc_cancer*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ai51tPmzoawn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}